{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "import os  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TYpes of log reg\n",
    "\n",
    "1. Binary (Pass/Fail)  -Activation function - Sigmoid\n",
    "2. Multi (Cats, Dogs, Sheep) - Activation function - Softmax\n",
    "3. Ordinal (Low, Medium, High) - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical variables\n",
    "\n",
    "- Nominal (No ordering)\n",
    "\n",
    "- ordinal (Order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Studied</th>\n",
       "      <th>Slept</th>\n",
       "      <th>Passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.855064</td>\n",
       "      <td>9.639962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.625440</td>\n",
       "      <td>0.058927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.828192</td>\n",
       "      <td>0.723199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.150955</td>\n",
       "      <td>3.899420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.477900</td>\n",
       "      <td>8.198181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Studied     Slept  Passed\n",
       "0  4.855064  9.639962       1\n",
       "1  8.625440  0.058927       0\n",
       "2  3.828192  0.723199       0\n",
       "3  7.150955  3.899420       1\n",
       "4  6.477900  8.198181       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'log_reg.csv'  \n",
    "data = pd.read_csv(path, header=None, names=['Studied', 'Slept', 'Passed'])  \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Studied</th>\n",
       "      <th>Slept</th>\n",
       "      <th>Passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.855064</td>\n",
       "      <td>9.639962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.625440</td>\n",
       "      <td>0.058927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.828192</td>\n",
       "      <td>0.723199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.150955</td>\n",
       "      <td>3.899420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.477900</td>\n",
       "      <td>8.198181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.922270</td>\n",
       "      <td>1.331427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.978216</td>\n",
       "      <td>0.993438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.635603</td>\n",
       "      <td>8.542803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.672359</td>\n",
       "      <td>5.416400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.866015</td>\n",
       "      <td>2.042671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.861405</td>\n",
       "      <td>9.655310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.540421</td>\n",
       "      <td>2.590374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.717881</td>\n",
       "      <td>5.381662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.181297</td>\n",
       "      <td>0.171475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.560140</td>\n",
       "      <td>0.024946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.971369</td>\n",
       "      <td>4.188302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.438203</td>\n",
       "      <td>1.943812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.357551</td>\n",
       "      <td>9.887983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.540332</td>\n",
       "      <td>6.713873</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.549102</td>\n",
       "      <td>9.375132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8.081974</td>\n",
       "      <td>9.842207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.620465</td>\n",
       "      <td>2.099328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.834771</td>\n",
       "      <td>3.152204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.753449</td>\n",
       "      <td>4.219243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.043213</td>\n",
       "      <td>2.609765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.196383</td>\n",
       "      <td>7.475745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.910070</td>\n",
       "      <td>8.232928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.529619</td>\n",
       "      <td>4.905512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.859112</td>\n",
       "      <td>5.691868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.557179</td>\n",
       "      <td>1.644672</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.132488</td>\n",
       "      <td>3.264912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7.746528</td>\n",
       "      <td>3.643019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7.065360</td>\n",
       "      <td>1.121328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.505817</td>\n",
       "      <td>0.863102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5.700529</td>\n",
       "      <td>7.083544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6.660467</td>\n",
       "      <td>2.253956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.091472</td>\n",
       "      <td>7.084377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4.903088</td>\n",
       "      <td>6.025478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3.443109</td>\n",
       "      <td>7.066347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>8.182978</td>\n",
       "      <td>0.974987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>9.000376</td>\n",
       "      <td>9.549328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>9.683104</td>\n",
       "      <td>9.507050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2.991911</td>\n",
       "      <td>5.299210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2.238183</td>\n",
       "      <td>4.534844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.665478</td>\n",
       "      <td>9.782636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6.779319</td>\n",
       "      <td>2.028181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>9.947841</td>\n",
       "      <td>1.026458</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3.214849</td>\n",
       "      <td>0.485059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8.851646</td>\n",
       "      <td>1.027916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.200058</td>\n",
       "      <td>4.834060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.185470</td>\n",
       "      <td>0.732631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>7.260088</td>\n",
       "      <td>3.974134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>9.150516</td>\n",
       "      <td>2.562334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>6.460896</td>\n",
       "      <td>7.076293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>4.778572</td>\n",
       "      <td>8.282871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.022280</td>\n",
       "      <td>2.658428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>7.630637</td>\n",
       "      <td>7.405351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3.684997</td>\n",
       "      <td>5.049965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7.484260</td>\n",
       "      <td>6.059396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.030708</td>\n",
       "      <td>3.937267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Studied     Slept  Passed\n",
       "0   4.855064  9.639962       1\n",
       "1   8.625440  0.058927       0\n",
       "2   3.828192  0.723199       0\n",
       "3   7.150955  3.899420       1\n",
       "4   6.477900  8.198181       1\n",
       "5   1.922270  1.331427       0\n",
       "6   8.978216  0.993438       1\n",
       "7   6.635603  8.542803       1\n",
       "8   7.672359  5.416400       1\n",
       "9   4.866015  2.042671       0\n",
       "10  6.861405  9.655310       1\n",
       "11  8.540421  2.590374       1\n",
       "12  3.717881  5.381662       0\n",
       "13  9.181297  0.171475       1\n",
       "14  9.560140  0.024946       0\n",
       "15  5.971369  4.188302       1\n",
       "16  9.438203  1.943812       1\n",
       "17  4.357551  9.887983       1\n",
       "18  4.540332  6.713873       1\n",
       "19  1.549102  9.375132       0\n",
       "20  8.081974  9.842207       1\n",
       "21  9.620465  2.099328       1\n",
       "22  8.834771  3.152204       1\n",
       "23  1.753449  4.219243       0\n",
       "24  1.043213  2.609765       0\n",
       "25  1.196383  7.475745       0\n",
       "26  8.910070  8.232928       1\n",
       "27  4.529619  4.905512       1\n",
       "28  1.859112  5.691868       0\n",
       "29  9.557179  1.644672       1\n",
       "..       ...       ...     ...\n",
       "70  1.132488  3.264912       0\n",
       "71  7.746528  3.643019       1\n",
       "72  7.065360  1.121328       0\n",
       "73  6.505817  0.863102       0\n",
       "74  5.700529  7.083544       1\n",
       "75  6.660467  2.253956       0\n",
       "76  1.091472  7.084377       0\n",
       "77  4.903088  6.025478       0\n",
       "78  3.443109  7.066347       0\n",
       "79  8.182978  0.974987       1\n",
       "80  9.000376  9.549328       1\n",
       "81  9.683104  9.507050       1\n",
       "82  2.991911  5.299210       0\n",
       "83  2.238183  4.534844       0\n",
       "84  0.665478  9.782636       1\n",
       "85  6.779319  2.028181       0\n",
       "86  9.947841  1.026458       1\n",
       "87  3.214849  0.485059       0\n",
       "88  8.851646  1.027916       1\n",
       "89  0.200058  4.834060       0\n",
       "90  5.185470  0.732631       0\n",
       "91  7.260088  3.974134       1\n",
       "92  9.150516  2.562334       1\n",
       "93  6.460896  7.076293       1\n",
       "94  4.778572  8.282871       1\n",
       "95  0.022280  2.658428       0\n",
       "96  7.630637  7.405351       1\n",
       "97  3.684997  5.049965       0\n",
       "98  7.484260  6.059396       1\n",
       "99  2.030708  3.937267       0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):  \n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "#logistic regression\n",
    "#similar to linear regression \n",
    "#--- Activation function (map predicted values to probabilities) -- o/p (probabilities | (0 0r 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24563819208>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAHVCAYAAADywj0dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x245638191d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nums = np.arange(-10, 10, step=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))  \n",
    "ax.plot(nums, sigmoid(nums), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(features, weights):\n",
    "  z = np.dot(features, weights)\n",
    "  return sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = w0 + w1*x1 + w2*x2\n",
    "\n",
    "Main idea - to calculate weights\n",
    "\n",
    "cost function (linear reg - Mean sq.error)\n",
    "\n",
    "Optimization algo (min the cost or max. )\n",
    "\n",
    "Objective function (Optimizatino algo + cost function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prediction function is a non-linear function (sigmoid) , squaring the prediction (which we do in MSE) \n",
    "# results in a non - convex function with many local minimums \n",
    "\n",
    "\n",
    "#if fn has many local minimums gradient descent won't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_function(features, labels, weights):\n",
    "    observations = len(labels)\n",
    "\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #Take the error when label=1\n",
    "    class1_cost = -labels*np.log(predictions)\n",
    "\n",
    "    #Take the error when label=0\n",
    "    class2_cost = (1-labels)*np.log(1-predictions)\n",
    "\n",
    "    #Take the sum of both costs\n",
    "    cost = class1_cost - class2_cost\n",
    "\n",
    "    #Take the average cost\n",
    "    cost = cost.sum()/observations\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculate gradient average\n",
    "\n",
    "multiplied by the learning rate\n",
    "\n",
    "subtracted from weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(features, labels, weights, lr):\n",
    "    N = len(features)\n",
    "\n",
    "    #1 - Get Predictions\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #2 Transpose features from (200, 3) to (3, 200)\n",
    "    # So we can multiply w the (200,1)  cost matrix.\n",
    "    # Returns a (3,1) matrix holding 3 partial derivatives --\n",
    "    # one for each feature -- representing the aggregate\n",
    "    # slope of the cost function across all observations\n",
    "    gradient = np.dot(features.T,  predictions - labels)\n",
    "\n",
    "    #3 Take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "\n",
    "    #4 - Multiply the gradient by our learning rate\n",
    "    gradient *= lr\n",
    "\n",
    "    #5 - Subtract from our weights to minimize cost\n",
    "    weights -= gradient\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decision_boundary(prob):\n",
    "  return 1 if prob >= .5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision - recall curves to find the optimum threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(preds):\n",
    "  decision_boundary = np.vectorize(decision_boundary)\n",
    "  return decision_boundary(predictions).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Probabilities = [ 0.967, 0.448, 0.015, 0.780, 0.978, 0.004]\n",
    "Classifications = [1, 0, 0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(features, labels, weights, lr, iters):\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        weights = update_weights(features, labels, weights, lr)\n",
    "\n",
    "        #Calculate error for auditing purposes\n",
    "        cost = cost_function(features, labels, weights)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Log Progress\n",
    "        if i % 1000 == 0:\n",
    "            print \"iter: \"+str(i) + \" cost: \"+str(cost)\n",
    "\n",
    "    return weights, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predicted_labels, actual_labels):\n",
    "    diff = predicted_labels - actual_labels\n",
    "    return 1.0 - (float(np.count_nonzero(diff)) / len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Multi class classification - \n",
    "\n",
    "Multi label classification - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
