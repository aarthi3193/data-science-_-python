{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "> Cluster is a group of similar objects (observations, examples, members, customers, patients, locations, etc)\n",
    "\n",
    "> Finding the groups of cases/observations/objectsin the population such that the objects are\n",
    "\n",
    "    * Homogeneous within the group (high intra-classimilarity)\n",
    "    * Heterogeneous between the groups(low inter-classimilarity )\n",
    "    * Intra-cluster distances are minimized\n",
    "    * Inter-cluster distances are maximized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Market Segmentation\n",
    "Credit Risk\n",
    "Insurance\n",
    "Image Segmentation\n",
    "News Article Clustering\n",
    "Clustering Languages\n",
    "Anomaly Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "> Partitionalclustering or non-hierarchical\n",
    "\n",
    "> Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "euclidean distance - sq.root((x2-x1)^2 + (y2-y1)^2)\n",
    "\n",
    "manhattan distance = abs(x2-x1) + abs(y2-y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "> Select a distance measure\n",
    "\n",
    "> Select a clustering algorithm\n",
    "\n",
    "> Determine the number of clusters\n",
    "\n",
    "> run the clustering algo\n",
    "\n",
    "> Validate the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "> To measure similarity between two observations a distance measure is needed. \n",
    "\n",
    "> For a single variable, similarity is straightforward\n",
    "\n",
    "> Multiple variables require an aggregate distance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "> k-means clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "> The number k of clusters is fixed\n",
    "\n",
    "> Initialize k cluster centers\n",
    "\n",
    "> Do\n",
    "    * Assignment step: Assign each data point to its closest cluster center\n",
    "    * Re-estimation step: Re-compute cluster centers\n",
    " \n",
    "> While(there are still changes in the cluster centers)\n",
    "    * Continue till there is no significant change between two iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deciding the number of clusters\n",
    "\n",
    "assign 3 cluster centers\n",
    "\n",
    "for each obs - calculate distance b\\w that point and each cluster and assign the obs to the cluster with min distance\n",
    "\n",
    "recalculate cluster center\n",
    "\n",
    "do this step for every obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first iter\n",
    "\n",
    "10 points - \n",
    "\n",
    "Calculate the distance of each case (observation) from all clusters\n",
    "\n",
    "> Assign each case (observation) to nearest cluster\n",
    "\n",
    "> Re calculate the cluster centers (simple methos - mean , centroid) - ((x1, y1), (x2, y2) - mean = ((x1+x2)/2, (y1+y2)/2)\n",
    "\n",
    "> Reassign after changing the cluster centers\n",
    "\n",
    "c1 - cluster 1 center\n",
    "\n",
    "c2 - cluster 2 center\n",
    "\n",
    "c3 - cluster3 center\n",
    "    \n",
    "                                                                        \n",
    "\n",
    "second iter                                                                      \n",
    " \n",
    "10 points - \n",
    "\n",
    "Calculate the distance of each case (observation) from all clusters\n",
    "\n",
    "> Assign each case (observation) to nearest cluster\n",
    "\n",
    "> Re calculate the cluster centers (simple methos - mean , centroid) - ((x1, y1), (x2, y2) - mean = ((x1+x2)/2, (y1+y2)/2)\n",
    "\n",
    "> Reassign after changing the cluster centers\n",
    "\n",
    "c1_1 - cluster 1 center\n",
    "\n",
    "c2 - cluster 2 center\n",
    "\n",
    "c3 - cluster3 center\n",
    "    \n",
    " \n",
    "c1_1 - c1 = x\n",
    "\n",
    "if x < 0.005; stop\n",
    "\n",
    "stoppage criterion - convergence\n",
    "                                                \n",
    "                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "> Overall population\n",
    "\n",
    "> Fix the number of clusters (Randomnly initialize cluster centers)\n",
    "\n",
    "> Calculate the distance of each case (observation) from all clusters\n",
    "\n",
    "> Assign each case (observation) to nearest cluster\n",
    "\n",
    "> Re calculate the cluster centers (simple method - mean , centroid) - ((x1, y1), (x2, y2) - mean = ((x1+x2)/2, (y1+y2)/2)\n",
    "\n",
    "> Reassign after changing the cluster centers\n",
    "\n",
    "> Continue till there is no significant change (cluster center) between two iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stoppage criteria -\n",
    "\n",
    "https://static.googleusercontent.com/media/research.google.com/vi//pubs/archive/42853.pdf\n",
    "\n",
    "K-means converges after 20-50 iterations in all practical situations, even on high dimensional datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> Elbow plot\n",
    "\n",
    "Compute clustering algorithm (e.g., k-means clustering) for different values of k. For instance, by varying k from 1 to 10 clusters.\n",
    "\n",
    "For each k, calculate the total within-cluster sum of square (wss).\n",
    "(Sum of squared distances between items and the corresponding centroid)\n",
    "\n",
    "Plot the curve of wss according to the number of clusters k.\n",
    "\n",
    "The location of a bend (knee) in the plot is generally considered as an indicator of the appropriate number of clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
